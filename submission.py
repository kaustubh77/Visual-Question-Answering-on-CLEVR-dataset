# -*- coding: utf-8 -*-
"""final_submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f2kSHE-9GYTXnsZddLRJ8_sV8VBwviwR
"""

import os, argparse
import cv2, spacy, numpy as np
from keras.models import model_from_json
from keras.optimizers import SGD
from sklearn.externals import joblib

import numpy as np 
import pandas as pd 
import os

from numpy import array
from keras.preprocessing.text import one_hot
from keras.models import Sequential
from keras.layers import Flatten
import os

from sklearn.feature_extraction.text import CountVectorizer
from keras.preprocessing.text import Tokenizer
from keras.models import Model
from keras.layers import Dense, Embedding, LSTM, Input
from sklearn.model_selection import train_test_split
from keras.utils.np_utils import to_categorical
import re
from keras.layers.embeddings import Embedding

from sklearn.feature_extraction.text import CountVectorizer
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.layers import Dense, Embedding, LSTM, Input,CuDNNLSTM
from sklearn.model_selection import train_test_split
from keras.utils.np_utils import to_categorical
import re

from keras.models import load_model
model = load_model('./model1.h5')

import pickle

with open('./tokenizer.pickle','rb') as handle:
    tokenizer=pickle.load(handle)

import json
from pprint import pprint
with open('./Questions.json') as f:
  data=json.load(f)

data2=pd.DataFrame(data.get("questions",None))

X1 = tokenizer.texts_to_sequences(data2['Question'].values)
max_length_of_text=200
X1 = pad_sequences(X1, maxlen=max_length_of_text)

from skimage.io import imread
from skimage.transform import resize
import numpy as np

from keras.utils import Sequence
class VQAgen(Sequence):

    def __init__(self, x_set,RNN_train, batch_size):
        self.x, self.x2 = x_set,RNN_train #y_set
        self.batch_size = batch_size

    def __len__(self):
        return int(np.ceil(len(self.x) / float(self.batch_size)))

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_x2= self.x2[idx * self.batch_size:(idx + 1) * self.batch_size]
        temp_list=[]
        for R in batch_x2:
         temp_list.append(R)
        
        temp_list32=[]
        for imgname in batch_x:
          im =resize(imread(imgname), (32, 32, 3))
          temp_list32.append(im) 
       
          
        return [np.array(temp_list32),np.array(temp_list)]

PATH1 = "./images/"
image_name_list=[]
for img in data2['Image']:
  image_name_list.append(PATH1+img+'.png')

test_data_gen=VQAgen(image_name_list,X1,64)

dic = {
    0:'0',
    1:'true',
    2:'2',
    3:'3',
    4:'4',
    5:'5',
    6:'6',
    7:'7',
    8:'8',
    9:'cube',
    10:'sphere',
    11:'large',
    12:'small',
    13:'yellow',
    14:'cyan',
    15:'brown',
    16:'gray',
    17:'purple',
    18:'blue',
    19:'red',
    20:'green',
    21:'cylinder',
    22:'metal',
    23:'rubber'
}

y_pred = model.predict_generator(test_data_gen, len(image_name_list) //64 + 1, verbose = 1)
y_pred = np.argmax(y_pred, axis = 1)
y_pred = [ dic.get( y_pred[index] )   for index in range(len(y_pred)) ]

new_df=pd.DataFrame({"Index":data2['Index'].values.tolist(),"Answer":y_pred})
cols = new_df.columns.tolist()
cols = cols[-1:] + cols[:-1]
new_df=new_df[cols]
new_df.to_csv("./solution.csv",index=False)